{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilizing ProteinEmbedding and Dataset formation\n",
    "\n",
    "The _ProteinEmbedding_ object can store protein sequences in combination with embedding and vector representations,\n",
    "which can then be manipulated by implementing standard operations from the __skbio__ library. \n",
    "\n",
    "To demonstrate this process, we will read in a list of protein sequences, then attempt to create a dataset from our \n",
    "embeddings to be streamed in with the standard skbio.read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "from skbio.embedding import ProteinEmbedding\n",
    "from skbio.sequence import Protein\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import skbio\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Embeddings\n",
    "\n",
    "This function will take the inputted protein sequences and feed it through an embedding model (prot-t5), \n",
    "outputting the generated embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_protein_t5_embedding(sequence, model_name, tokenizer_name):\n",
    "    import torch\n",
    "    from transformers import T5Tokenizer, T5EncoderModel\n",
    "    # (In case we want to use ONNX model)\n",
    "    # from optimum.onnxruntime import ORTModel\n",
    "    \n",
    "    tokenizer = T5Tokenizer.from_pretrained(tokenizer_name)\n",
    "    model = T5EncoderModel.from_pretrained(model_name)\n",
    "\n",
    "    # convert sequence to formatted list of strings\n",
    "    seq_list = []\n",
    "    seq_list.append(sequence)\n",
    "    seqs = [\" \".join(list(re.sub(r\"[UZOB]\", \"X\", str(seq)))) for seq in seq_list]\n",
    "    \n",
    "    # tokenize sequences and pad up to the longest sequence in the batch\n",
    "    ids = tokenizer.batch_encode_plus(seqs, add_special_tokens=True, padding=\"longest\")\n",
    "    input_ids = torch.tensor(ids['input_ids'])\n",
    "    attention_mask = torch.tensor(ids['attention_mask'])\n",
    "\n",
    "    # generate embeddings\n",
    "    with torch.no_grad():\n",
    "        embedding_repr = model(input_ids=input_ids,attention_mask=attention_mask)\n",
    "        \n",
    "    return ProteinEmbedding(embedding_repr.last_hidden_state.detach().cpu().numpy()[0][:-1], sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse arguments\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# Modify the default values of the arguments to match the desired values\n",
    "parser.add_argument(\"--n_sequences\", type=int, default=20)\n",
    "parser.add_argument(\"--model_name\", type=str, default=\"Rostlab/prot_t5_xl_uniref50\")\n",
    "parser.add_argument(\"--tokenizer_name\", type=str, default=\"Rostlab/prot_t5_xl_uniref50\")\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "#need str like object\n",
    "sequence_list = skbio.read('test.fa', format='fasta', constructor=Protein)\n",
    "#sequence_list = list(skbio.read('test.fa', format='fasta', constructor=Protein))[:args.n_sequences]\n",
    "#print(sequence_list[0].sequence)\n",
    "loaded_proteins = lambda sequence: load_protein_t5_embedding(sequence, args.model_name, args.tokenizer_name)\n",
    "\n",
    "\n",
    "embed_list = (loaded_proteins(x) for x in sequence_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to file\n",
    "\n",
    "Here, we can write our loaded embeddings to a .h5 file using skbio.write. To verify that the embeddings were stored correctly, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pbatra6/miniforge3/envs/.env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.05566912  0.05675846 -0.16483116 ...  0.05404978  0.01345288\n",
      "   0.03236827]\n",
      " [ 0.14818218  0.12554237 -0.2660721  ...  0.1882809  -0.05386918\n",
      "   0.09356216]\n",
      " [ 0.14772612  0.10723014 -0.21425001 ...  0.05648247  0.2655668\n",
      "  -0.05122016]\n",
      " ...\n",
      " [ 0.12038261  0.15324979  0.13185279 ...  0.22860621 -0.15126939\n",
      "  -0.09792379]\n",
      " [-0.02801923  0.04539812 -0.05980184 ...  0.07925158 -0.08836559\n",
      "  -0.17490435]\n",
      " [ 0.09879396  0.21208242  0.15040213 ...  0.20142882 -0.02289281\n",
      "  -0.08747597]]\n",
      "[[-0.08464682 -0.12554063 -0.16223185 ...  0.21731049  0.5165856\n",
      "  -0.03173729]\n",
      " [-0.09767824 -0.04928781 -0.1939477  ...  0.17679492  0.1372093\n",
      "  -0.18649372]\n",
      " [-0.01484734 -0.09123899 -0.21456687 ...  0.14749224 -0.2751867\n",
      "  -0.2023742 ]\n",
      " ...\n",
      " [-0.19169022  0.01500933  0.2335486  ...  0.28378057 -0.20650242\n",
      "  -0.32116067]\n",
      " [ 0.11082172  0.00871864 -0.1059447  ...  0.097903   -0.28522074\n",
      "  -0.00503905]\n",
      " [ 0.0339542  -0.21907638  0.08403985 ...  0.02584727 -0.15630914\n",
      "  -0.45342624]]\n"
     ]
    }
   ],
   "source": [
    "#embed_list = map(loaded_proteins, sequence_list)\n",
    "# Issue: Generator should include iterables\n",
    "skbio.write(embed_list, format='embed', into=\"bagel.h5\")\n",
    "\n",
    "#test if the file was written correctly and output\n",
    "read_embed = iter(skbio.read(\"bagel.h5\", format='embed' ,constructor=ProteinEmbedding))\n",
    "for item in read_embed:\n",
    "    print(item.embedding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
