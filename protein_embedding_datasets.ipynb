{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilizing ProteinEmbedding and Dataset formation\n",
    "\n",
    "The _ProteinEmbedding_ object can store protein sequences in combination with embedding and vector representations,\n",
    "which can then be manipulated by implementing standard operations from the __skbio__ library. \n",
    "\n",
    "To demonstrate this process, we will read in a list of protein sequences, then attempt to create a dataset from our \n",
    "embeddings to be streamed in with the standard skbio.read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "from skbio.embedding import ProteinEmbedding\n",
    "from skbio.sequence import Protein\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import argparse\n",
    "import skbio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Protein Sequences\n",
    "\n",
    "We will now create a function to generate a list of random proteins (of size args.n_prots) to be embedded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_proteins(n_prots):\n",
    "    import numpy as np\n",
    "    PROTEIN_ALPHABET = \"ACDEFGHIKLMNPQRSTVWY\"\n",
    "    np.random.seed(42)\n",
    "    proteins = []\n",
    "    for _ in range(n_prots):\n",
    "        prot = \"\".join(\n",
    "            np.random.choice(list(PROTEIN_ALPHABET),\n",
    "                             size=np.random.randint(20, 100)))\n",
    "        proteins.append(prot)\n",
    "    return proteins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading FASTA File\n",
    "\n",
    "_Bagel.fa_ is a file containing bacteriocin sequences stored in FASTA format. We will parse this\n",
    "file and use the output to create our __ProteinEmbedding__ object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read a fasta file and return a list of sequences\n",
    "def ReadFastaFile(filename, n_sequences):\n",
    "  fileObj = open(filename, 'r')\n",
    "  sequences = []\n",
    "  seqFragments = []\n",
    "  for line in fileObj:\n",
    "    if line.startswith('>'):\n",
    "      if(len(sequences) == n_sequences-1):\n",
    "        break\n",
    "      if seqFragments:\n",
    "        sequence = ''.join(seqFragments)\n",
    "        sequences.append(sequence)\n",
    "      seqFragments = []\n",
    "    else:\n",
    "      seq = line.rstrip()\n",
    "      seqFragments.append(seq)\n",
    "  if seqFragments:\n",
    "    sequence = ''.join(seqFragments)\n",
    "    sequences.append(sequence)\n",
    "  fileObj.close()\n",
    "  return sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Embeddings\n",
    "\n",
    "This function will take the inputted protein sequences and feed it through an embedding model (prot-t5), \n",
    "outputting the generated embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_protein_t5_embedding(sequence, model_name, tokenizer_name):\n",
    "    import torch\n",
    "    from transformers import T5Tokenizer, T5EncoderModel\n",
    "    # (In case we want to use ONNX model)\n",
    "    # from optimum.onnxruntime import ORTModel\n",
    "    tokenizer = T5Tokenizer.from_pretrained(tokenizer_name)\n",
    "    model = T5EncoderModel.from_pretrained(model_name)\n",
    "\n",
    "    # tokenize sequences and pad up to the longest sequence in the batch\n",
    "    ids = tokenizer.batch_encode_plus(sequence, add_special_tokens=True, padding=\"longest\")\n",
    "    input_ids = torch.tensor(ids['input_ids'])\n",
    "    attention_mask = torch.tensor(ids['attention_mask'])\n",
    "\n",
    "    # generate embeddings\n",
    "    with torch.no_grad():\n",
    "        embedding_repr = model(input_ids=input_ids,attention_mask=attention_mask)\n",
    "        \n",
    "    return embedding_repr.last_hidden_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passing to file\n",
    "\n",
    "Finally, we can output the embeddings into a \"test.h5\" file, which can be utilized further\n",
    "as will be demonstrated in other scikit-bio tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accepted protein sequences:  ['CLGVGSCNNFAGCGYAIVCFW', 'MVRLLAKLLRSTIHGSNGVSLDAVSSTHGTPGFQTPDARVISRFGFN'] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accepted protein sequence:  CLGVGSCNNFAGCGYAIVCFW \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [01:22<01:22, 82.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accepted protein sequence:  MVRLLAKLLRSTIHGSNGVSLDAVSSTHGTPGFQTPDARVISRFGFN \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [03:27<00:00, 103.67s/it]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ProteinEmbedding' object has no attribute 'metadata'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m read_embed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(skbio\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbagel.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membed\u001b[39m\u001b[38;5;124m'\u001b[39m ,constructor\u001b[38;5;241m=\u001b[39mProteinEmbedding))\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m read_embed:\n\u001b[0;32m---> 31\u001b[0m     \u001b[38;5;28mprint\u001b[39m(item\u001b[38;5;241m.\u001b[39membedding\u001b[38;5;241m.\u001b[39mshape, \u001b[43mitem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ProteinEmbedding' object has no attribute 'metadata'"
     ]
    }
   ],
   "source": [
    "# parse arguments\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# Modify the default values of the arguments to match the desired values\n",
    "parser.add_argument(\"--n_sequences\", type=int, default=2)\n",
    "parser.add_argument(\"--model_name\", type=str, default=\"Rostlab/prot_t5_xl_uniref50\")\n",
    "parser.add_argument(\"--tokenizer_name\", type=str, default=\"Rostlab/prot_t5_xl_uniref50\")\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "# Parse bagel.fa\n",
    "sequence_list = ReadFastaFile(\"bagel.fa\", args.n_sequences)\n",
    "embed_list = []\n",
    "print(\"Accepted protein sequences: \", sequence_list, \"\\n\")\n",
    "\n",
    "# Embed the random/inputted protein sequence(s)\n",
    "for sequence in tqdm(sequence_list):\n",
    "    print(\"Accepted protein sequence: \", sequence, \"\\n\")\n",
    "    test_embed = load_protein_t5_embedding(sequence, args.model_name, args.tokenizer_name).numpy()\n",
    "    #reshape embeddings to fit the skbio format\n",
    "    embed_list.append(test_embed.reshape(test_embed.shape[0], -1))\n",
    "\n",
    "# cast embeddings to ProteinEmbedding object and reshape to fit hdf5 format\n",
    "embedding_sequence_list = [(embedding, sequence) for embedding, sequence in zip(embed_list, sequence_list)]\n",
    "embedding_repr = lambda x: ProteinEmbedding(*x)\n",
    "embed_objs = (x for x in map(embedding_repr, embedding_sequence_list))\n",
    "skbio.write(embed_objs, format='embed', into=\"bagel.h5\")\n",
    "\n",
    "#test if the file was written correctly and output\n",
    "read_embed = iter(skbio.read(\"bagel.h5\", format='embed' ,constructor=ProteinEmbedding))\n",
    "for item in read_embed:\n",
    "    print(item.embedding)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
