{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating and searching against vector databases with TM-Vec\n",
    "\n",
    "To form protein databases that are easily stored using vector embeddings, we will:\n",
    "1. Feed ProTrans embeddings into out TM-Vec model\n",
    "2. Generate a DB of protein vectors\n",
    "3. Search against our DB and plot the results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Refer to protein_embedding_datasets.ipynb for further explanation of functions in utils.py__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_protein_t5_embedding, read_fasta_file\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Embed a protein using tm_vec (takes as input a prottrans embedding)\n",
    "def embed_tm_vec(prottrans_embedding, model_deep, device):\n",
    "    padding = torch.zeros(prottrans_embedding.shape[0:2]).type(torch.BoolTensor)\n",
    "    tm_vec_embedding = model_deep(prottrans_embedding, src_mask=None, src_key_padding_mask=padding)\n",
    "\n",
    "    return(tm_vec_embedding.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse arguments\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# Modify the default values of the arguments to match the desired values\n",
    "parser.add_argument(\"--n_sequences\", type=int, default=20)\n",
    "parser.add_argument(\"--model_name\", type=str, default=\"Rostlab/prot_t5_xl_uniref50\")\n",
    "parser.add_argument(\"--tokenizer_name\", type=str, default=\"Rostlab/prot_t5_xl_uniref50\")\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "# Parse bagel.fa\n",
    "sequence_list = read_fasta_file(\"bagel.fa\", args.n_sequences)\n",
    "embed_list = []\n",
    "print(\"Accepted protein sequences: \", sequence_list, \"\\n\")\n",
    "\n",
    "# Embed the random/inputted protein sequence(s)\n",
    "for sequence in tqdm(sequence_list):\n",
    "    print(\"Accepted protein sequence: \", sequence, \"\\n\")\n",
    "    test_embed = load_protein_t5_embedding(sequence, args.model_name, args.tokenizer_name).numpy()\n",
    "    #reshape embeddings to fit the skbio format\n",
    "    embed_list.append(test_embed.reshape(test_embed.shape[0], -1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
