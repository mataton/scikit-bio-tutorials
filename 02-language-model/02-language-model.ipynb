{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cfaOQykOA3r"
      },
      "source": [
        "# Embeddings and Vectors with Scikit-Bio\n",
        "\n",
        "**Welcome to scikit-bio tutorial-02!** In this tutorial, we will showcase how the scikit-bio library can be utilized for embedding and vectorizing sets of protein sequences. Our goal is to demonstrate sequence classification and structural alignment using *TM-Vec* and *DeepBLAST* respectively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQnrfNbnOA3u"
      },
      "source": [
        "### Introduction - a role of deep learning in `scikit-bio`\n",
        "he application of deep learning in biology is gaining widespread popularity, with protein language models (pLMs) being a notable success story. By generating protein embeddings from sequence data, pLMs have paved the way for a range of innovative applications, including, for instance, fluorescent protein design by [ESM3](https://techcrunch.com/2024/06/25/evolutionaryscale-backed-by-amazon-and-nvidia-raises-142m-for-protein-generating-ai/) and [CRISPR-Cas design](https://www.biorxiv.org/content/10.1101/2024.04.22.590591v1).\n",
        "\n",
        "Compared to traditional letter-encoded amino acids, protein embeddings offer a more expressive representation of a protein. In addition to sequence information, they encode structural, evolutionary (including organism of origin), and functional (such as thermostability and fluorescence) properties. These embeddings can be viewed as a compressed representation of multiple sequence alignments (MSAs), and thus, any task that benefits from MSA will also benefit from operations on embeddings. As computational optimizations of protein language models (pLMs) continue to emerge, embeddings-based methods are likely to gain popularity. Our goal is to provide an infrastructure that enables users to conduct sequence analysis leveraging embeddings.\n",
        "\n",
        "However, not all tasks benefit from embeddings. The limitations of embeddings are discussed in detail in [Li et al., 2024](https://www.biorxiv.org/content/10.1101/2024.02.05.578959v2.abstract)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Nf-rJkLOA3w"
      },
      "source": [
        "### What is TM-Vec?\n",
        "[TM-Vec](https://www.nature.com/articles/s41587-023-01917-2) is a tool that utilises protein representations from pLM in order to predict structural similarity of two proteins.\n",
        "### How does TM-Vec work?\n",
        "General protein representations (also called \"embeddings\"), that are predictive of protein structure, are obtained from pLM (ProtT5). Next, they are modified into vectors with the help of TM-Vec, which is another neural network. TM-Vec encodes proteins in a way that allows the cosine distance between two vectors to approximate structural similarity (measure via TM-score), thereby eliminating the need for time-consuming structure prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MSwJVIAcOA3x"
      },
      "outputs": [],
      "source": [
        "# ignore the warnings\n",
        "# they are a result of the lack of GPU in Colab\n",
        "# the software was tested with them\n",
        "\n",
        "from importlib.util import find_spec\n",
        "if find_spec('skbio') is None:\n",
        "    !pip install -q scikit-bio\n",
        "\n",
        "if find_spec('tmvec') is None:\n",
        "    !pip install -q git+https://github.com/valentynbez/tmvec.git\n",
        "\n",
        "if find_spec('onnx') is None:\n",
        "    !pip install -q onnx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "5DV1eSXoOA30",
        "outputId": "334069f1-88aa-46fc-c673-125c83ca5c5b"
      },
      "outputs": [],
      "source": [
        "import skbio\n",
        "skbio.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qb0D5YFqOA32",
        "outputId": "07ce3f56-3894-41ea-c50a-115e25b2d9c9"
      },
      "outputs": [],
      "source": [
        "# get data\n",
        "!mkdir data\n",
        "!wget -q -O ./data/pdb_hits.fa \"https://raw.githubusercontent.com/scikit-bio/scikit-bio-tutorials/main/02-language-model/data/pdb_hits.fa\"\n",
        "!wget -q -O ./data/bacteriocin.csv \"https://raw.githubusercontent.com/scikit-bio/scikit-bio-tutorials/main/02-language-model/data/bagel_bacteriocins_all_classes.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHZWhs4lOA33"
      },
      "outputs": [],
      "source": [
        "# All Necessary imports\n",
        "from skbio.embedding import ProteinEmbedding, ProteinVector\n",
        "from tmvec.embedding import ProtT5Encoder\n",
        "from skbio.alignment import TabularMSA\n",
        "from skbio.sequence import Protein\n",
        "import matplotlib.pyplot as plt\n",
        "import skbio.embedding as emb\n",
        "from skbio.io import read\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Vz5B2XHOA33"
      },
      "source": [
        "### Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UewAqLbTOA33"
      },
      "outputs": [],
      "source": [
        "# Helper Functions for Embedding Sequences\n",
        "def load_protein_t5_embedding(sequence, model_path, tokenizer_path):\n",
        "\n",
        "    embedder = ProtT5Encoder(model_path=model_path, tokenizer_path=tokenizer_path,\n",
        "                             backend=\"onnx\", local_files_only=False)\n",
        "\n",
        "    # generate embeddings\n",
        "    emb = embedder.get_sequence_embeddings([sequence])[0]\n",
        "\n",
        "    return ProteinEmbedding(emb, sequence)\n",
        "\n",
        "\n",
        "def to_embeddings(sequences : list, model_name, tokenizer_name):\n",
        "    # Embed the random/inputted protein sequence(s)\n",
        "    for sequence in tqdm(sequences):\n",
        "        test_embed = load_protein_t5_embedding(str(sequence), model_name, tokenizer_name)\n",
        "        #reshape embeddings to fit the skbio format\n",
        "        yield test_embed\n",
        "\n",
        "def align(x, y, model):\n",
        "    pred_alignment = model.align(str(x), str(y))\n",
        "    return pred_alignment\n",
        "\n",
        "\n",
        "def predict_aln_matrix(query_seq, target_seq, model):\n",
        "    x_code = get_sequence(str(query_seq), model.tokenizer)[0].to(model.device)\n",
        "    y_code = get_sequence(str(target_seq), model.tokenizer)[0].to(model.device)\n",
        "    seq, order = pack_sequences([x_code], [y_code])\n",
        "    with torch.no_grad():\n",
        "        gen = model.aligner.traceback(seq, order)\n",
        "    _, aln_mat = next(gen)\n",
        "\n",
        "    return aln_mat.squeeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGg4C7PqOA34"
      },
      "outputs": [],
      "source": [
        "# Load_vector function for vectors\n",
        "def load_vectors(file_path, sequence_list : list):\n",
        "      data = np.load(file_path, allow_pickle=True)\n",
        "      vectors = data['embeddings']\n",
        "\n",
        "      protein_vectors = [ProteinVector(vector, sequence) for vector, sequence in zip(vectors, sequence_list)]\n",
        "      return protein_vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJaGOMm6OA34"
      },
      "source": [
        "### Part 1: Embedding sequences to file\n",
        "\n",
        "We're going to start by reading in the bacteriocin sequences with `skbio.read`, then storing the embedded sequences in `ProteinEmbedding` objects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJwkZ5LXOA34"
      },
      "outputs": [],
      "source": [
        "# a model we prepared for a faster execution on CPU\n",
        "model_path = \"scikit-bio/prot-t5-xl-uniref50-onnx\"\n",
        "# tokenizer from standard repo\n",
        "tokenizer_path = \"Rostlab/prot_t5_xl_uniref50\"\n",
        "\n",
        "# Parse bagel.fa\n",
        "sequence_list = read(\"data/pdb_hits.fa\", format='fasta')\n",
        "embed_list = to_embeddings(sequence_list, model_path, tokenizer_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCMb2horOA35",
        "outputId": "69e48322-c372-43d3-fa88-2a0ed4235b89"
      },
      "outputs": [],
      "source": [
        "# this cell will take sometime, because the model is being downloaded in the background\n",
        "# after first run each sequence will be processed significantly faster\n",
        "next(embed_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaRa-sufOA35"
      },
      "source": [
        "### Part 2: Building vector-DB and plot Ordination"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwFP_HunOA35"
      },
      "source": [
        "We can directly feed our FASTA file into the tmvec build_db __CLI__ function, which will output our\n",
        "vectors as a .npz file in the specified directory.\n",
        "\n",
        "This function takes in as an input:\n",
        "1. --input-fasta: A FASTA file containing your sequences.\n",
        "2. --output: the file location to output to."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hr2nK-TCOA35",
        "outputId": "244d2d80-b9ae-49f5-b1a6-2ecb62f28b49"
      },
      "outputs": [],
      "source": [
        "# please, ignore the warnings\n",
        "# majority of DL libraries expect to see a GPU chip\n",
        "# we made it work on CPU, and warnings are not an issue\n",
        "!tmvec build-db --input-fasta data/pdb_hits.fa --output outputs/pdb_hits_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsFE_IffOA36"
      },
      "source": [
        "With the proteins encoded as vectors within a database, we can extract the vectors and\n",
        "cast them to ProteinVectors objects, which can then be used to visualize the structural similarity between the proteins"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "PQZinb1qOA36",
        "outputId": "9d5fd007-41cb-4168-a616-4a37a6af8c8c"
      },
      "outputs": [],
      "source": [
        "# load sequences\n",
        "sequence_list = read(\"data/pdb_hits.fa\", format='fasta')\n",
        "\n",
        "#read in vectors to generator object\n",
        "vec_generator = load_vectors(\"outputs/pdb_hits_output.npz\", sequence_list)\n",
        "\n",
        "# convert the vectors into an OrdinationResults object for plotting\n",
        "ord_results = emb.embed_vec_to_ordination(vec_generator)\n",
        "\n",
        "# read in the bacterion sequence / function metadata\n",
        "df = pd.read_csv(\"data/bacteriocin.csv\")\n",
        "df = df.dropna(subset=['Sequence']).set_index('Sequence')\n",
        "df = df.groupby('Sequence').first()\n",
        "# match the sequence ids to the rows in the metadata\n",
        "common_ids = list(set(ord_results.samples.index) & set(df.index))\n",
        "\n",
        "df = df.loc[common_ids]\n",
        "\n",
        "ord_results.samples = ord_results.samples.loc[common_ids]\n",
        "\n",
        "# plot the results\n",
        "ord_results.plot(df, column='class', title='Bacteriocin Sequence TM-Scores');"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
