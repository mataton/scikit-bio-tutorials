{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56732b74-ca01-40d1-9ffa-621d393e5bbb",
   "metadata": {},
   "source": [
    "# Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09d0fc4c-7402-418b-949f-016cdf9225a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "from skbio.embedding import ProteinEmbedding\n",
    "from skbio.sequence import Protein\n",
    "from tqdm import tqdm\n",
    "import skbio\n",
    "\n",
    "import torch\n",
    "\n",
    "from deepblast.utils import load_model\n",
    "from skbio.alignment import PairAlignPath\n",
    "from deepblast.dataset.utils import get_sequence, pack_sequences, revstate_f\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def condense_cigar(cigar_str):\n",
    "    \"\"\"\n",
    "    Convert full length to condensed CIGAR\n",
    "    Example: MMMIIII = 3M4I\n",
    "    \"\"\"\n",
    "    condensed_cigar = ''\n",
    "    current_state = ''\n",
    "    count = 0\n",
    "    for i in range(len(cigar_str)):\n",
    "        if cigar_str[i] == current_state:\n",
    "            count += 1\n",
    "        else:\n",
    "            if count > 0:\n",
    "                condensed_cigar += str(count) + current_state\n",
    "            current_state = cigar_str[i]\n",
    "            count = 1\n",
    "    condensed_cigar += str(count) + current_state\n",
    "    return condensed_cigar\n",
    "\n",
    "\n",
    "def tm_to_cigar(tm_alignment_string, condensed=False):\n",
    "    \"\"\"\n",
    "    Convert TMalign style alignment string to CIGAR string\n",
    "    \"\"\"\n",
    "\n",
    "    cigar = ''\n",
    "\n",
    "    for state in tm_alignment_string:\n",
    "        if state == ':':\n",
    "            cigar += 'M'\n",
    "        elif state == '1':\n",
    "            cigar += 'I'\n",
    "        elif state == '2':\n",
    "            cigar += 'D'\n",
    "\n",
    "    return cigar\n",
    "\n",
    "def align(x, y, model):\n",
    "    pred_alignment = model.align(str(x), str(y))\n",
    "    # TODO : need to convert TMalign style string to cigar\n",
    "    cigar = tm_to_cigar(pred_alignment)\n",
    "    cigar = condense_cigar(cigar)\n",
    "    path = PairAlignPath.from_cigar(cigar)\n",
    "    return path\n",
    "\n",
    "\n",
    "def predict_aln_matrix(query_seq, target_seq, model):\n",
    "    x_code = get_sequence(str(query_seq), model.tokenizer)[0].to(model.device)\n",
    "    y_code = get_sequence(str(target_seq), model.tokenizer)[0].to(model.device)\n",
    "    seq, order = pack_sequences([x_code], [y_code])\n",
    "    with torch.no_grad():\n",
    "        gen = model.aligner.traceback(seq, order)\n",
    "    _, aln_mat = next(gen)\n",
    "\n",
    "    return aln_mat.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c873a6ee-7e85-48c1-b5d0-c8b5717e76c8",
   "metadata": {},
   "source": [
    "# Align sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ecea75c-81a6-4581-b0a9-32e60ce32228",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Rostlab/prot_t5_xl_uniref50\"\n",
    "tokenizer_name = \"Rostlab/prot_t5_xl_uniref50\"\n",
    "from skbio import Protein\n",
    "\n",
    "# Parse bagel.fa\n",
    "sequence_list = skbio.io.read(\"bagel.fa\", format='fasta', constructor=Protein)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70f8a845-1a3a-49a5-84e0-5d286e02e77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "1it [00:06,  6.67s/it]"
     ]
    }
   ],
   "source": [
    "x = next(sequence_list)\n",
    "y = next(sequence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8819fd2d-5126-45a3-b4d8-9ace7eee79a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# smith-waterman errored out because of the sting/path length missmatch\n",
    "\n",
    "model = load_model(\"/nfs/cds-peta/exports/biol_micro_cds_gr_sunagawa/scratch/vbezshapkin/tm-vec/models/deepblast-v3.ckpt\", device=\"cpu\",\n",
    "                   alignment_mode=\"smith-waterman\"\n",
    "                   )\n",
    "\n",
    "path = align(x, y, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbccbc2",
   "metadata": {},
   "source": [
    "## Visualize Predicted Alignment Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f18b0ba-5be5-41ff-b37e-9e4d8c6da8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = predict_aln_matrix(x, y, model)\n",
    "\n",
    "# visualise matrix with cbar\n",
    "plt.imshow(matrix, cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.show();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
